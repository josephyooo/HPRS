{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e434c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from PIL import Image, ImageEnhance, ImageOps, ImageFilter\n",
    "import random\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision.io import read_image\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78cba03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory containing the augmented images\n",
    "\"\"\"\n",
    "y'all should copy the directory where you have stored your files on your local PC\n",
    "\"\"\"\n",
    "data_dir = \"C:\\\\Users\\\\wisea\\\\Transfer\\\\Deep_Learning_Files\\\\ProjectFilles\\\\Data\"\n",
    "\n",
    "# Define the transformations to be applied to the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18b618ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load and augment images from a directory\n",
    "def augment_images(directory, num_augments):\n",
    "    augmented_images = []\n",
    "    for filename in os.listdir(directory):\n",
    "        # Load the original image\n",
    "        image_path = os.path.join(directory, filename)\n",
    "        original_image = Image.open(image_path)\n",
    "        \n",
    "        # Apply transformations to the original image\n",
    "        for _ in range(num_augments):\n",
    "            # Randomly select augmentation techniques\n",
    "            chosen_transforms = random.sample(transform_options, k=random.randint(1, max_transforms))\n",
    "            composed_transform = transforms.Compose(chosen_transforms)\n",
    "            augmented_image = composed_transform(original_image)\n",
    "            augmented_images.append(transform(augmented_image))\n",
    "    return augmented_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c5f992a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the subfolders containing the images\n",
    "subfolders = ['Alopecia-Pictures', 'seborrheic-dermatitis-pictures', 'Psoriasis-pictures']\n",
    "\n",
    "# Create a dictionary to store augmented images for each subfolder\n",
    "augmented_images_by_subfolder = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e335a539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define augmentation strategy\n",
    "augmentation_strategy = {\n",
    "    'Alopecia-Pictures': {\n",
    "        'less_than_50': 6,\n",
    "        'between_50_and_100': 4,\n",
    "        'more_than_100': 2\n",
    "    },\n",
    "    'seborrheic-dermatitis-pictures': {\n",
    "        'less_than_50': 6,\n",
    "        'between_50_and_100': 4,\n",
    "        'more_than_100': 2\n",
    "    },\n",
    "    'Psoriasis-pictures': {\n",
    "        'less_than_50': 6,\n",
    "        'between_50_and_100': 4,\n",
    "        'more_than_100': 2\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf7fb9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation techniques\n",
    "transform_options = [\n",
    "    transforms.RandomRotation(degrees=30),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomGrayscale(p=0.1),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5)\n",
    "]\n",
    "max_transforms = len(transform_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7acebbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augment images for each subfolder based on the strategy\n",
    "for subfolder in subfolders:\n",
    "    subfolder_path = os.path.join(data_dir, subfolder)\n",
    "    num_images = len(os.listdir(subfolder_path))\n",
    "    num_augments = None\n",
    "    if num_images < 50:\n",
    "        num_augments = augmentation_strategy[subfolder]['less_than_50']\n",
    "    elif 50 <= num_images <= 100:\n",
    "        num_augments = augmentation_strategy[subfolder]['between_50_and_100']\n",
    "    else:\n",
    "        num_augments = augmentation_strategy[subfolder]['more_than_100']\n",
    "        \n",
    "    augmented_images = augment_images(subfolder_path, num_augments=num_augments)\n",
    "    augmented_images_by_subfolder[subfolder] = augmented_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f3b6fb41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subfolder: Alopecia-Pictures, Tensor size: torch.Size([328, 3, 224, 224])\n",
      "Subfolder: seborrheic-dermatitis-pictures, Tensor size: torch.Size([240, 3, 224, 224])\n",
      "Subfolder: Psoriasis-pictures, Tensor size: torch.Size([202, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# Convert the augmented images to torch tensors\n",
    "augmented_images_tensors_by_subfolder = {}\n",
    "for subfolder, images in augmented_images_by_subfolder.items():\n",
    "    augmented_images_tensors_by_subfolder[subfolder] = torch.stack(images)\n",
    "\n",
    "# Display the size of tensors for each subfolder\n",
    "for subfolder, tensors in augmented_images_tensors_by_subfolder.items():\n",
    "    print(f\"Subfolder: {subfolder}, Tensor size: {tensors.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0bf5f1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Showing images from subfolder: Alopecia-Pictures\n"
     ]
    }
   ],
   "source": [
    "# Display 20 pictures from each subfolder\n",
    "for subfolder, images in augmented_images_by_subfolder.items():\n",
    "    print(f\"\\nShowing images from subfolder: {subfolder}\")\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    for i in range(20):  # Displaying 20 images from each subfolder\n",
    "        plt.subplot(2, 10, i + 1)\n",
    "        plt.imshow(images[i].permute(1, 2, 0))\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cec877e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all augmented images and create labels\n",
    "all_images = torch.cat([torch.stack(images) for images in augmented_images_by_subfolder.values()], dim=0)\n",
    "num_classes = len(subfolders)\n",
    "all_labels = torch.tensor(sum([[i] * len(images) for i, images in enumerate(augmented_images_by_subfolder.values())], []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3c34f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and validation sets\n",
    "dataset = list(zip(all_images, all_labels))\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ef30809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 616\n",
      "Validation set size: 154\n"
     ]
    }
   ],
   "source": [
    "# Define DataLoader for training and validation sets\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Check the sizes of training and validation sets\n",
    "print(f\"Training set size: {len(train_dataset)}\")\n",
    "print(f\"Validation set size: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e4f07e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42268f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, cardinality=32):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        mid_channels = out_channels // 2\n",
    "        self.conv1 = ConvBlock(in_channels, mid_channels, kernel_size=1)\n",
    "        self.conv2 = ConvBlock(mid_channels, mid_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.conv3 = nn.Conv2d(mid_channels, out_channels, kernel_size=1)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        self.cardinality = cardinality\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = self.conv3(out)\n",
    "        out += self.downsample(residual)\n",
    "        out = self.bn(out)\n",
    "        out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66dc6f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNeXt(nn.Module):\n",
    "    def __init__(self, num_blocks, cardinality, num_classes=3):\n",
    "        super(ResNeXt, self).__init__()\n",
    "        self.conv1 = ConvBlock(3, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self.make_layer(64, 256, num_blocks[0], stride=1, cardinality=cardinality)\n",
    "        self.layer2 = self.make_layer(256, 512, num_blocks[1], stride=2, cardinality=cardinality)\n",
    "        self.layer3 = self.make_layer(512, 1024, num_blocks[2], stride=2, cardinality=cardinality)\n",
    "        self.layer4 = self.make_layer(1024, 2048, num_blocks[3], stride=2, cardinality=cardinality)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(2048, num_classes)\n",
    "\n",
    "    def make_layer(self, in_channels, out_channels, num_blocks, stride, cardinality):\n",
    "        layers = []\n",
    "        layers.append(ResidualBlock(in_channels, out_channels, stride, cardinality))\n",
    "        for _ in range(1, num_blocks):\n",
    "            layers.append(ResidualBlock(out_channels, out_channels, cardinality=cardinality))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10f8e6ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb28c6f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNeXt(\n",
      "  (conv1): ConvBlock(\n",
      "    (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (conv1): ConvBlock(\n",
      "        (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (conv2): ConvBlock(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResidualBlock(\n",
      "      (conv1): ConvBlock(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (conv2): ConvBlock(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential()\n",
      "    )\n",
      "    (2): ResidualBlock(\n",
      "      (conv1): ConvBlock(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (conv2): ConvBlock(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (conv1): ConvBlock(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (conv2): ConvBlock(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResidualBlock(\n",
      "      (conv1): ConvBlock(\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (conv2): ConvBlock(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential()\n",
      "    )\n",
      "    (2): ResidualBlock(\n",
      "      (conv1): ConvBlock(\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (conv2): ConvBlock(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential()\n",
      "    )\n",
      "    (3): ResidualBlock(\n",
      "      (conv1): ConvBlock(\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (conv2): ConvBlock(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (conv1): ConvBlock(\n",
      "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (conv2): ConvBlock(\n",
      "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResidualBlock(\n",
      "      (conv1): ConvBlock(\n",
      "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (conv2): ConvBlock(\n",
      "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential()\n",
      "    )\n",
      "    (2): ResidualBlock(\n",
      "      (conv1): ConvBlock(\n",
      "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (conv2): ConvBlock(\n",
      "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential()\n",
      "    )\n",
      "    (3): ResidualBlock(\n",
      "      (conv1): ConvBlock(\n",
      "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (conv2): ConvBlock(\n",
      "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential()\n",
      "    )\n",
      "    (4): ResidualBlock(\n",
      "      (conv1): ConvBlock(\n",
      "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (conv2): ConvBlock(\n",
      "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential()\n",
      "    )\n",
      "    (5): ResidualBlock(\n",
      "      (conv1): ConvBlock(\n",
      "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (conv2): ConvBlock(\n",
      "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (conv1): ConvBlock(\n",
      "        (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (conv2): ConvBlock(\n",
      "        (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResidualBlock(\n",
      "      (conv1): ConvBlock(\n",
      "        (conv): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (conv2): ConvBlock(\n",
      "        (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential()\n",
      "    )\n",
      "    (2): ResidualBlock(\n",
      "      (conv1): ConvBlock(\n",
      "        (conv): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (conv2): ConvBlock(\n",
      "        (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "model = ResNeXt(num_blocks=[3, 4, 6, 3], cardinality=32, num_classes=3).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b22df27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "547113f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 1.0055, Train Acc: 0.5503, Val Loss: 3.7804, Val Acc: 0.3247\n",
      "Epoch 2/10, Train Loss: 0.7622, Train Acc: 0.6753, Val Loss: 1.0915, Val Acc: 0.5390\n",
      "Epoch 3/10, Train Loss: 0.7787, Train Acc: 0.6429, Val Loss: 1.0122, Val Acc: 0.5390\n",
      "Epoch 4/10, Train Loss: 0.7294, Train Acc: 0.6737, Val Loss: 0.8164, Val Acc: 0.6169\n",
      "Epoch 5/10, Train Loss: 0.7765, Train Acc: 0.6591, Val Loss: 1.3404, Val Acc: 0.4416\n",
      "Epoch 6/10, Train Loss: 0.7787, Train Acc: 0.6786, Val Loss: 1.3730, Val Acc: 0.4740\n",
      "Epoch 7/10, Train Loss: 0.7713, Train Acc: 0.6981, Val Loss: 1.1110, Val Acc: 0.5779\n",
      "Epoch 8/10, Train Loss: 0.7679, Train Acc: 0.6672, Val Loss: 1.3210, Val Acc: 0.3896\n",
      "Epoch 9/10, Train Loss: 0.6718, Train Acc: 0.7240, Val Loss: 0.7368, Val Acc: 0.6948\n",
      "Epoch 10/10, Train Loss: 0.6523, Train Acc: 0.7305, Val Loss: 2.8089, Val Acc: 0.3961\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_accuracy = correct / total\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for val_images, val_labels in val_loader:\n",
    "            val_outputs = model(val_images)\n",
    "            val_loss = criterion(val_outputs, val_labels)\n",
    "            val_running_loss += val_loss.item()\n",
    "            _, val_predicted = torch.max(val_outputs, 1)\n",
    "            val_total += val_labels.size(0)\n",
    "            val_correct += (val_predicted == val_labels).sum().item()\n",
    "    val_loss = val_running_loss / len(val_loader)\n",
    "    val_accuracy = val_correct / val_total\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
    "          f\"Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, \"\n",
    "          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8492e0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Inside the train_model function\n",
    "for inputs, labels in train_loader:\n",
    "    inputs, labels = inputs.to(device), labels.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a76d1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
