{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f7d380dc210>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from utils import finetune\n",
    "from data_prep import DermNet\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetune GoogLeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25 | Learning Rate 0.0001\n",
      "----------\n",
      "train Loss: 0.9156 Acc: 0.7500\n",
      "val Loss: 0.6805 Acc: 0.8239\n",
      "\n",
      "Epoch 2/25 | Learning Rate 0.0001\n",
      "----------\n",
      "train Loss: 0.4920 Acc: 0.8477\n",
      "val Loss: 0.4161 Acc: 0.8662\n",
      "\n",
      "Epoch 3/25 | Learning Rate 0.0001\n",
      "----------\n",
      "train Loss: 0.3478 Acc: 0.8891\n",
      "val Loss: 0.3515 Acc: 0.8768\n",
      "\n",
      "Epoch 4/25 | Learning Rate 0.0001\n",
      "----------\n",
      "train Loss: 0.2798 Acc: 0.9093\n",
      "val Loss: 0.4024 Acc: 0.8627\n",
      "\n",
      "Epoch 5/25 | Learning Rate 0.0001\n",
      "----------\n",
      "train Loss: 0.2386 Acc: 0.9217\n",
      "val Loss: 0.2183 Acc: 0.9049\n",
      "\n",
      "Epoch 6/25 | Learning Rate 0.0001\n",
      "----------\n",
      "train Loss: 0.1952 Acc: 0.9349\n",
      "val Loss: 0.2626 Acc: 0.9085\n",
      "\n",
      "Epoch 7/25 | Learning Rate 0.0001\n",
      "----------\n",
      "train Loss: 0.1847 Acc: 0.9437\n",
      "val Loss: 0.4240 Acc: 0.8380\n",
      "\n",
      "Epoch 8/25 | Learning Rate 1e-05\n",
      "----------\n",
      "train Loss: 0.1566 Acc: 0.9498\n",
      "val Loss: 0.4246 Acc: 0.8310\n",
      "\n",
      "Epoch 9/25 | Learning Rate 1e-05\n",
      "----------\n",
      "train Loss: 0.1740 Acc: 0.9410\n",
      "val Loss: 0.2884 Acc: 0.8908\n",
      "\n",
      "Epoch 10/25 | Learning Rate 1e-05\n",
      "----------\n",
      "train Loss: 0.1476 Acc: 0.9560\n",
      "val Loss: 0.2311 Acc: 0.9014\n",
      "\n",
      "Epoch 11/25 | Learning Rate 1e-05\n",
      "----------\n",
      "train Loss: 0.1370 Acc: 0.9533\n",
      "val Loss: 0.2868 Acc: 0.8803\n",
      "\n",
      "Epoch 12/25 | Learning Rate 1e-05\n",
      "----------\n",
      "train Loss: 0.1411 Acc: 0.9577\n",
      "val Loss: 0.1639 Acc: 0.9401\n",
      "\n",
      "Epoch 13/25 | Learning Rate 1e-05\n",
      "----------\n",
      "train Loss: 0.1270 Acc: 0.9648\n",
      "val Loss: 0.4610 Acc: 0.8099\n",
      "\n",
      "Epoch 14/25 | Learning Rate 1e-05\n",
      "----------\n",
      "train Loss: 0.1315 Acc: 0.9613\n",
      "val Loss: 0.2474 Acc: 0.8979\n",
      "\n",
      "Epoch 15/25 | Learning Rate 1.0000000000000002e-06\n",
      "----------\n",
      "train Loss: 0.1173 Acc: 0.9630\n",
      "val Loss: 0.1819 Acc: 0.9331\n",
      "\n",
      "Epoch 16/25 | Learning Rate 1.0000000000000002e-06\n",
      "----------\n",
      "train Loss: 0.1366 Acc: 0.9569\n",
      "val Loss: 0.2482 Acc: 0.9155\n",
      "\n",
      "Epoch 17/25 | Learning Rate 1.0000000000000002e-06\n",
      "----------\n",
      "train Loss: 0.1282 Acc: 0.9613\n",
      "val Loss: 0.1833 Acc: 0.9401\n",
      "\n",
      "Epoch 18/25 | Learning Rate 1.0000000000000002e-06\n",
      "----------\n",
      "train Loss: 0.1351 Acc: 0.9586\n",
      "val Loss: 0.3701 Acc: 0.8415\n",
      "\n",
      "Epoch 19/25 | Learning Rate 1.0000000000000002e-06\n",
      "----------\n",
      "train Loss: 0.1319 Acc: 0.9595\n",
      "val Loss: 0.2891 Acc: 0.8944\n",
      "\n",
      "Epoch 20/25 | Learning Rate 1.0000000000000002e-06\n",
      "----------\n",
      "train Loss: 0.1656 Acc: 0.9472\n",
      "val Loss: 0.2225 Acc: 0.9155\n",
      "\n",
      "Epoch 21/25 | Learning Rate 1.0000000000000002e-06\n",
      "----------\n",
      "train Loss: 0.1206 Acc: 0.9560\n",
      "val Loss: 0.1608 Acc: 0.9331\n",
      "\n",
      "Epoch 22/25 | Learning Rate 1.0000000000000002e-07\n",
      "----------\n",
      "train Loss: 0.1253 Acc: 0.9630\n",
      "val Loss: 0.3545 Acc: 0.8732\n",
      "\n",
      "Epoch 23/25 | Learning Rate 1.0000000000000002e-07\n",
      "----------\n",
      "train Loss: 0.1414 Acc: 0.9577\n",
      "val Loss: 0.3348 Acc: 0.8627\n",
      "\n",
      "Epoch 24/25 | Learning Rate 1.0000000000000002e-07\n",
      "----------\n",
      "train Loss: 0.1544 Acc: 0.9533\n",
      "val Loss: 0.2094 Acc: 0.9155\n",
      "\n",
      "Epoch 25/25 | Learning Rate 1.0000000000000002e-07\n",
      "----------\n",
      "train Loss: 0.1497 Acc: 0.9525\n",
      "val Loss: 0.2292 Acc: 0.9085\n",
      "\n",
      "Training complete in 3m 45s\n",
      "Best val Acc: 0.940141\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import GoogLeNet_Weights\n",
    "\n",
    "from models import GoogLeNet_Scalp\n",
    "\n",
    "dataset = DermNet(transform=GoogLeNet_Weights.DEFAULT.transforms())\n",
    "finetune(GoogLeNet_Scalp, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetune AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25 | Learning Rate 0.0001\n",
      "----------\n",
      "train Loss: 0.6654 Acc: 0.7606\n",
      "val Loss: 0.2887 Acc: 0.8662\n",
      "\n",
      "Epoch 2/25 | Learning Rate 0.0001\n",
      "----------\n",
      "train Loss: 0.3879 Acc: 0.8442\n",
      "val Loss: 0.3397 Acc: 0.9014\n",
      "\n",
      "Epoch 3/25 | Learning Rate 0.0001\n",
      "----------\n",
      "train Loss: 0.4645 Acc: 0.8327\n",
      "val Loss: 0.2457 Acc: 0.9014\n",
      "\n",
      "Epoch 4/25 | Learning Rate 0.0001\n",
      "----------\n",
      "train Loss: 0.3098 Acc: 0.8794\n",
      "val Loss: 0.2964 Acc: 0.8556\n",
      "\n",
      "Epoch 5/25 | Learning Rate 0.0001\n",
      "----------\n",
      "train Loss: 0.2644 Acc: 0.9005\n",
      "val Loss: 0.1617 Acc: 0.9401\n",
      "\n",
      "Epoch 6/25 | Learning Rate 0.0001\n",
      "----------\n",
      "train Loss: 0.2796 Acc: 0.8908\n",
      "val Loss: 0.3189 Acc: 0.8838\n",
      "\n",
      "Epoch 7/25 | Learning Rate 0.0001\n",
      "----------\n",
      "train Loss: 0.2172 Acc: 0.9217\n",
      "val Loss: 0.1832 Acc: 0.9296\n",
      "\n",
      "Epoch 8/25 | Learning Rate 1e-05\n",
      "----------\n",
      "train Loss: 0.2435 Acc: 0.9014\n",
      "val Loss: 0.1833 Acc: 0.9261\n",
      "\n",
      "Epoch 9/25 | Learning Rate 1e-05\n",
      "----------\n",
      "train Loss: 0.2053 Acc: 0.9225\n",
      "val Loss: 0.1781 Acc: 0.9120\n",
      "\n",
      "Epoch 10/25 | Learning Rate 1e-05\n",
      "----------\n",
      "train Loss: 0.1783 Acc: 0.9340\n",
      "val Loss: 0.1838 Acc: 0.9437\n",
      "\n",
      "Epoch 11/25 | Learning Rate 1e-05\n",
      "----------\n",
      "train Loss: 0.2313 Acc: 0.9093\n",
      "val Loss: 0.1714 Acc: 0.9296\n",
      "\n",
      "Epoch 12/25 | Learning Rate 1e-05\n",
      "----------\n",
      "train Loss: 0.1585 Acc: 0.9393\n",
      "val Loss: 0.1571 Acc: 0.9366\n",
      "\n",
      "Epoch 13/25 | Learning Rate 1e-05\n",
      "----------\n",
      "train Loss: 0.1780 Acc: 0.9393\n",
      "val Loss: 0.1741 Acc: 0.9225\n",
      "\n",
      "Epoch 14/25 | Learning Rate 1e-05\n",
      "----------\n",
      "train Loss: 0.1674 Acc: 0.9366\n",
      "val Loss: 0.2351 Acc: 0.9155\n",
      "\n",
      "Epoch 15/25 | Learning Rate 1.0000000000000002e-06\n",
      "----------\n",
      "train Loss: 0.1777 Acc: 0.9313\n",
      "val Loss: 0.1900 Acc: 0.9296\n",
      "\n",
      "Epoch 16/25 | Learning Rate 1.0000000000000002e-06\n",
      "----------\n",
      "train Loss: 0.2159 Acc: 0.9164\n",
      "val Loss: 0.2169 Acc: 0.9049\n",
      "\n",
      "Epoch 17/25 | Learning Rate 1.0000000000000002e-06\n",
      "----------\n",
      "train Loss: 0.1409 Acc: 0.9498\n",
      "val Loss: 0.1422 Acc: 0.9437\n",
      "\n",
      "Epoch 18/25 | Learning Rate 1.0000000000000002e-06\n",
      "----------\n",
      "train Loss: 0.1827 Acc: 0.9269\n",
      "val Loss: 0.2051 Acc: 0.9190\n",
      "\n",
      "Epoch 19/25 | Learning Rate 1.0000000000000002e-06\n",
      "----------\n",
      "train Loss: 0.1877 Acc: 0.9357\n",
      "val Loss: 0.1675 Acc: 0.9437\n",
      "\n",
      "Epoch 20/25 | Learning Rate 1.0000000000000002e-06\n",
      "----------\n",
      "train Loss: 0.1438 Acc: 0.9498\n",
      "val Loss: 0.1820 Acc: 0.9190\n",
      "\n",
      "Epoch 21/25 | Learning Rate 1.0000000000000002e-06\n",
      "----------\n",
      "train Loss: 0.1850 Acc: 0.9313\n",
      "val Loss: 0.1262 Acc: 0.9542\n",
      "\n",
      "Epoch 22/25 | Learning Rate 1.0000000000000002e-07\n",
      "----------\n",
      "train Loss: 0.1804 Acc: 0.9296\n",
      "val Loss: 0.1362 Acc: 0.9437\n",
      "\n",
      "Epoch 23/25 | Learning Rate 1.0000000000000002e-07\n",
      "----------\n",
      "train Loss: 0.1335 Acc: 0.9463\n",
      "val Loss: 0.1392 Acc: 0.9507\n",
      "\n",
      "Epoch 24/25 | Learning Rate 1.0000000000000002e-07\n",
      "----------\n",
      "train Loss: 0.1644 Acc: 0.9349\n",
      "val Loss: 0.1654 Acc: 0.9472\n",
      "\n",
      "Epoch 25/25 | Learning Rate 1.0000000000000002e-07\n",
      "----------\n",
      "train Loss: 0.1638 Acc: 0.9357\n",
      "val Loss: 0.1574 Acc: 0.9366\n",
      "\n",
      "Training complete in 1m 36s\n",
      "Best val Acc: 0.954225\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import AlexNet_Weights\n",
    "\n",
    "from models import AlexNet_Scalp\n",
    "\n",
    "dataset = DermNet(transform=AlexNet_Weights.DEFAULT.transforms())\n",
    "finetune(AlexNet_Scalp, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetune ResNeXt50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jo-wubuntu/.cache/pypoetry/virtualenvs/cs4851-0jjlgGcu-py3.10/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNeXt50_32X4D_Weights.IMAGENET1K_V1`. You can also use `weights=ResNeXt50_32X4D_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25 | Learning Rate 0.0001\n",
      "----------\n",
      "train Loss: 0.6322 Acc: 0.7843\n",
      "val Loss: 0.4500 Acc: 0.8873\n",
      "\n",
      "Epoch 2/25 | Learning Rate 0.0001\n",
      "----------\n",
      "train Loss: 0.2502 Acc: 0.8996\n",
      "val Loss: 0.3300 Acc: 0.8732\n",
      "\n",
      "Epoch 3/25 | Learning Rate 0.0001\n",
      "----------\n",
      "train Loss: 0.1218 Acc: 0.9613\n",
      "val Loss: 0.3246 Acc: 0.8908\n",
      "\n",
      "Epoch 4/25 | Learning Rate 0.0001\n",
      "----------\n",
      "train Loss: 0.1083 Acc: 0.9613\n",
      "val Loss: 1.7782 Acc: 0.6620\n",
      "\n",
      "Epoch 5/25 | Learning Rate 0.0001\n",
      "----------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ResNeXt_Scalp\n\u001b[1;32m      5\u001b[0m dataset \u001b[38;5;241m=\u001b[39m DermNet(transform\u001b[38;5;241m=\u001b[39mResNeXt50_32X4D_Weights\u001b[38;5;241m.\u001b[39mDEFAULT\u001b[38;5;241m.\u001b[39mtransforms())\n\u001b[0;32m----> 6\u001b[0m \u001b[43mfinetune\u001b[49m\u001b[43m(\u001b[49m\u001b[43mResNeXt_Scalp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/cs4851/HPRS/utils.py:124\u001b[0m, in \u001b[0;36mfinetune\u001b[0;34m(model, dataset, batch_size, lr, eps, weight_decay, step_size, gamma, num_epochs, num_workers, pin_memory, benchmark)\u001b[0m\n\u001b[1;32m    121\u001b[0m optimizer_ft \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model_ft\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr, eps\u001b[38;5;241m=\u001b[39meps, weight_decay\u001b[38;5;241m=\u001b[39mweight_decay)\n\u001b[1;32m    122\u001b[0m lr_scheduler \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mStepLR(optimizer_ft, step_size\u001b[38;5;241m=\u001b[39mstep_size, gamma\u001b[38;5;241m=\u001b[39mgamma)\n\u001b[0;32m--> 124\u001b[0m model_ft \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_ft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_ft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugmenter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maugmenter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;66;03m# save model\u001b[39;00m\n\u001b[1;32m    128\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(model_ft\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweights/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_ft.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/cs4851/HPRS/utils.py:63\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloaders, criterion, optimizer, scheduler, num_epochs, device, augmenter)\u001b[0m\n\u001b[1;32m     60\u001b[0m             optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;66;03m# statistics\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m     running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m inputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     64\u001b[0m     running_corrects \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(preds \u001b[38;5;241m==\u001b[39m labels\u001b[38;5;241m.\u001b[39mdata)\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m phase \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torchvision.models import ResNeXt50_32X4D_Weights\n",
    "\n",
    "from models import ResNeXt_Scalp\n",
    "\n",
    "dataset = DermNet(transform=ResNeXt50_32X4D_Weights.DEFAULT.transforms())\n",
    "finetune(ResNeXt_Scalp, dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hair-deisease-cnn-project-sPLV6DJP-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
