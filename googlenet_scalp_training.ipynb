{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25 | Learning Rate 0.001\n",
      "----------\n",
      "train Loss: 0.1609 Acc: 0.9393\n",
      "val Loss: 0.4124 Acc: 0.8737\n",
      "\n",
      "Epoch 2/25 | Learning Rate 0.001\n",
      "----------\n",
      "train Loss: 0.1416 Acc: 0.9516\n",
      "val Loss: 0.3899 Acc: 0.8456\n",
      "\n",
      "Epoch 3/25 | Learning Rate 0.001\n",
      "----------\n",
      "train Loss: 0.1263 Acc: 0.9542\n",
      "val Loss: 0.3850 Acc: 0.8702\n",
      "\n",
      "Epoch 4/25 | Learning Rate 0.001\n",
      "----------\n",
      "train Loss: 0.1223 Acc: 0.9542\n",
      "val Loss: 0.4384 Acc: 0.8632\n",
      "\n",
      "Epoch 5/25 | Learning Rate 0.001\n",
      "----------\n",
      "train Loss: 0.1550 Acc: 0.9498\n",
      "val Loss: 0.3122 Acc: 0.8737\n",
      "\n",
      "Epoch 6/25 | Learning Rate 0.001\n",
      "----------\n",
      "train Loss: 0.0955 Acc: 0.9648\n",
      "val Loss: 0.4715 Acc: 0.8772\n",
      "\n",
      "Epoch 7/25 | Learning Rate 0.001\n",
      "----------\n",
      "train Loss: 0.0960 Acc: 0.9648\n",
      "val Loss: 0.5836 Acc: 0.7930\n",
      "\n",
      "Epoch 8/25 | Learning Rate 0.0001\n",
      "----------\n",
      "train Loss: 0.0940 Acc: 0.9692\n",
      "val Loss: 1.0497 Acc: 0.7333\n",
      "\n",
      "Epoch 9/25 | Learning Rate 0.0001\n",
      "----------\n",
      "train Loss: 0.0820 Acc: 0.9701\n",
      "val Loss: 0.4392 Acc: 0.8632\n",
      "\n",
      "Epoch 10/25 | Learning Rate 0.0001\n",
      "----------\n",
      "train Loss: 0.0376 Acc: 0.9877\n",
      "val Loss: 0.5296 Acc: 0.8281\n",
      "\n",
      "Epoch 11/25 | Learning Rate 0.0001\n",
      "----------\n",
      "train Loss: 0.0487 Acc: 0.9833\n",
      "val Loss: 0.2368 Acc: 0.9228\n",
      "\n",
      "Epoch 12/25 | Learning Rate 0.0001\n",
      "----------\n",
      "train Loss: 0.0380 Acc: 0.9912\n",
      "val Loss: 0.2471 Acc: 0.9263\n",
      "\n",
      "Epoch 13/25 | Learning Rate 0.0001\n",
      "----------\n",
      "train Loss: 0.0946 Acc: 0.9674\n",
      "val Loss: 0.2122 Acc: 0.9544\n",
      "\n",
      "Epoch 14/25 | Learning Rate 0.0001\n",
      "----------\n",
      "train Loss: 0.0524 Acc: 0.9833\n",
      "val Loss: 0.2290 Acc: 0.9193\n",
      "\n",
      "Epoch 15/25 | Learning Rate 1e-05\n",
      "----------\n",
      "train Loss: 0.0594 Acc: 0.9824\n",
      "val Loss: 0.4790 Acc: 0.8737\n",
      "\n",
      "Epoch 16/25 | Learning Rate 1e-05\n",
      "----------\n",
      "train Loss: 0.0430 Acc: 0.9886\n",
      "val Loss: 0.2244 Acc: 0.9333\n",
      "\n",
      "Epoch 17/25 | Learning Rate 1e-05\n",
      "----------\n",
      "train Loss: 0.0465 Acc: 0.9850\n",
      "val Loss: 0.3801 Acc: 0.8842\n",
      "\n",
      "Epoch 18/25 | Learning Rate 1e-05\n",
      "----------\n",
      "train Loss: 0.0471 Acc: 0.9824\n",
      "val Loss: 0.2187 Acc: 0.9333\n",
      "\n",
      "Epoch 19/25 | Learning Rate 1e-05\n",
      "----------\n",
      "train Loss: 0.0238 Acc: 0.9938\n",
      "val Loss: 0.2778 Acc: 0.9263\n",
      "\n",
      "Epoch 20/25 | Learning Rate 1e-05\n",
      "----------\n",
      "train Loss: 0.0378 Acc: 0.9877\n",
      "val Loss: 0.2788 Acc: 0.9228\n",
      "\n",
      "Epoch 21/25 | Learning Rate 1e-05\n",
      "----------\n",
      "train Loss: 0.0295 Acc: 0.9894\n",
      "val Loss: 0.2422 Acc: 0.9263\n",
      "\n",
      "Epoch 22/25 | Learning Rate 1.0000000000000002e-06\n",
      "----------\n",
      "train Loss: 0.0504 Acc: 0.9824\n",
      "val Loss: 0.3694 Acc: 0.8737\n",
      "\n",
      "Epoch 23/25 | Learning Rate 1.0000000000000002e-06\n",
      "----------\n",
      "train Loss: 0.0385 Acc: 0.9903\n",
      "val Loss: 0.1641 Acc: 0.9439\n",
      "\n",
      "Epoch 24/25 | Learning Rate 1.0000000000000002e-06\n",
      "----------\n",
      "train Loss: 0.0345 Acc: 0.9877\n",
      "val Loss: 0.4823 Acc: 0.8526\n",
      "\n",
      "Epoch 25/25 | Learning Rate 1.0000000000000002e-06\n",
      "----------\n",
      "train Loss: 0.0335 Acc: 0.9877\n",
      "val Loss: 0.4196 Acc: 0.8947\n",
      "\n",
      "Training complete in 3m 29s\n",
      "Best val Acc: 0.954386\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms.v2 as v2\n",
    "from torchvision.models import GoogLeNet_Weights\n",
    "\n",
    "from data_prep import DermNet, get_dataloaders\n",
    "from googlenet_scalp import GoogLeNet_Scalp\n",
    "from model_trainer import train_model\n",
    "\n",
    "# hyperparameters\n",
    "batch_size = 64\n",
    "lr = 1e-3\n",
    "eps = 1e-4\n",
    "weight_decay = 1e-4\n",
    "weight_decay = 0\n",
    "step_size = 7\n",
    "gamma = 0.1\n",
    "num_epochs = 25\n",
    "\n",
    "# optimizations\n",
    "num_workers = 12\n",
    "pin_memory = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# get transform and augment\n",
    "transform = GoogLeNet_Weights.DEFAULT.transforms()\n",
    "## Reference: https://sebastianraschka.com/blog/2023/data-augmentation-pytorch.html\n",
    "augmenter = v2.RandAugment()\n",
    "\n",
    "# get dataset and data loaders\n",
    "dataset = DermNet(transform=transform)\n",
    "num_classes = len(dataset.classes)\n",
    "train_loader, val_loader = get_dataloaders(\n",
    "    dataset=dataset, transform=transform, batch_size=batch_size,\n",
    "    num_workers=num_workers, pin_memory=pin_memory\n",
    ")\n",
    "dataloaders = {'train': train_loader, 'val': val_loader}\n",
    "\n",
    "# setup model\n",
    "model_ft = GoogLeNet_Scalp(device=device, num_classes=num_classes)\n",
    "model_ft.load_state_dict(torch.load('weights/model_checkpoint.pt'))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr=lr, eps=eps, weight_decay=weight_decay)\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer_ft, step_size=step_size, gamma=gamma)\n",
    "\n",
    "model_ft = train_model(model_ft, dataloaders, criterion, optimizer_ft, lr_scheduler,\n",
    "                        num_epochs=num_epochs, device=device, augmenter=augmenter)\n",
    "# save model\n",
    "torch.save(model_ft.state_dict(), 'weights/model_checkpoint.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hair-deisease-cnn-project-sPLV6DJP-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
