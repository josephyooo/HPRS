{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25 | Learning Rate 0.001\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jo-wubuntu/.cache/pypoetry/virtualenvs/hair-deisease-cnn-project-sPLV6DJP-py3.10/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.9117 Acc: 0.5337\n",
      "val Loss: 0.8187 Acc: 0.6667\n",
      "\n",
      "Epoch 2/25 | Learning Rate 0.001\n",
      "----------\n",
      "train Loss: 0.4139 Acc: 0.8427\n",
      "val Loss: 0.8076 Acc: 0.6889\n",
      "\n",
      "Epoch 3/25 | Learning Rate 0.001\n",
      "----------\n",
      "train Loss: 0.1779 Acc: 0.9438\n",
      "val Loss: 1.0335 Acc: 0.6667\n",
      "\n",
      "Epoch 4/25 | Learning Rate 0.001\n",
      "----------\n",
      "train Loss: 0.1834 Acc: 0.9326\n",
      "val Loss: 0.7443 Acc: 0.8222\n",
      "\n",
      "Epoch 5/25 | Learning Rate 0.001\n",
      "----------\n",
      "train Loss: 0.1037 Acc: 0.9719\n",
      "val Loss: 1.1559 Acc: 0.7333\n",
      "\n",
      "Epoch 6/25 | Learning Rate 0.001\n",
      "----------\n",
      "train Loss: 0.0633 Acc: 0.9888\n",
      "val Loss: 1.6511 Acc: 0.6667\n",
      "\n",
      "Epoch 7/25 | Learning Rate 0.001\n",
      "----------\n",
      "train Loss: 0.0891 Acc: 0.9607\n",
      "val Loss: 0.5927 Acc: 0.8222\n",
      "\n",
      "Epoch 8/25 | Learning Rate 0.0001\n",
      "----------\n",
      "train Loss: 0.0582 Acc: 0.9831\n",
      "val Loss: 0.8701 Acc: 0.7333\n",
      "\n",
      "Epoch 9/25 | Learning Rate 0.0001\n",
      "----------\n",
      "train Loss: 0.0457 Acc: 0.9888\n",
      "val Loss: 0.5889 Acc: 0.8222\n",
      "\n",
      "Epoch 10/25 | Learning Rate 0.0001\n",
      "----------\n",
      "train Loss: 0.0607 Acc: 0.9719\n",
      "val Loss: 0.5485 Acc: 0.8222\n",
      "\n",
      "Epoch 11/25 | Learning Rate 0.0001\n",
      "----------\n",
      "train Loss: 0.0543 Acc: 0.9775\n",
      "val Loss: 0.6691 Acc: 0.8222\n",
      "\n",
      "Epoch 12/25 | Learning Rate 0.0001\n",
      "----------\n",
      "train Loss: 0.0320 Acc: 0.9831\n",
      "val Loss: 0.4078 Acc: 0.8667\n",
      "\n",
      "Epoch 13/25 | Learning Rate 0.0001\n",
      "----------\n",
      "train Loss: 0.0387 Acc: 0.9888\n",
      "val Loss: 0.5407 Acc: 0.8889\n",
      "\n",
      "Epoch 14/25 | Learning Rate 0.0001\n",
      "----------\n",
      "train Loss: 0.0305 Acc: 0.9944\n",
      "val Loss: 0.5892 Acc: 0.8667\n",
      "\n",
      "Epoch 15/25 | Learning Rate 1e-05\n",
      "----------\n",
      "train Loss: 0.0268 Acc: 0.9888\n",
      "val Loss: 0.6925 Acc: 0.7778\n",
      "\n",
      "Epoch 16/25 | Learning Rate 1e-05\n",
      "----------\n",
      "train Loss: 0.0649 Acc: 0.9775\n",
      "val Loss: 0.5496 Acc: 0.8667\n",
      "\n",
      "Epoch 17/25 | Learning Rate 1e-05\n",
      "----------\n",
      "train Loss: 0.0288 Acc: 0.9831\n",
      "val Loss: 0.5016 Acc: 0.8889\n",
      "\n",
      "Epoch 18/25 | Learning Rate 1e-05\n",
      "----------\n",
      "train Loss: 0.0191 Acc: 0.9944\n",
      "val Loss: 0.4306 Acc: 0.9111\n",
      "\n",
      "Epoch 19/25 | Learning Rate 1e-05\n",
      "----------\n",
      "train Loss: 0.0191 Acc: 0.9944\n",
      "val Loss: 0.4278 Acc: 0.9333\n",
      "\n",
      "Epoch 20/25 | Learning Rate 1e-05\n",
      "----------\n",
      "train Loss: 0.0198 Acc: 0.9944\n",
      "val Loss: 0.4833 Acc: 0.8000\n",
      "\n",
      "Epoch 21/25 | Learning Rate 1e-05\n",
      "----------\n",
      "train Loss: 0.0306 Acc: 0.9888\n",
      "val Loss: 0.8872 Acc: 0.7778\n",
      "\n",
      "Epoch 22/25 | Learning Rate 1.0000000000000002e-06\n",
      "----------\n",
      "train Loss: 0.0177 Acc: 0.9888\n",
      "val Loss: 0.5415 Acc: 0.8444\n",
      "\n",
      "Epoch 23/25 | Learning Rate 1.0000000000000002e-06\n",
      "----------\n",
      "train Loss: 0.0170 Acc: 0.9944\n",
      "val Loss: 1.0225 Acc: 0.8000\n",
      "\n",
      "Epoch 24/25 | Learning Rate 1.0000000000000002e-06\n",
      "----------\n",
      "train Loss: 0.0209 Acc: 0.9944\n",
      "val Loss: 0.5046 Acc: 0.8889\n",
      "\n",
      "Epoch 25/25 | Learning Rate 1.0000000000000002e-06\n",
      "----------\n",
      "train Loss: 0.0605 Acc: 0.9888\n",
      "val Loss: 0.6099 Acc: 0.8444\n",
      "\n",
      "Training complete in 1m 20s\n",
      "Best val Acc: 0.933333\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms.v2 as v2\n",
    "from torchvision.models import GoogLeNet_Weights\n",
    "\n",
    "from data_prep import DermNet, get_dataloaders\n",
    "from googlenet_scalp import GoogLeNet_Scalp\n",
    "from model_trainer import train_model\n",
    "\n",
    "# hyperparameters\n",
    "batch_size = 64\n",
    "lr = 1e-3\n",
    "eps = 1e-4\n",
    "weight_decay = 1e-3\n",
    "step_size = 7\n",
    "gamma = 0.1\n",
    "num_epochs = 25\n",
    "\n",
    "# optimizations\n",
    "num_workers = 12\n",
    "pin_memory = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# get transform and augment\n",
    "transform = GoogLeNet_Weights.DEFAULT.transforms()\n",
    "augmenter = v2.AugMix()\n",
    "\n",
    "# get dataset and data loaders\n",
    "dataset = DermNet(transform=transform)\n",
    "num_classes = len(dataset.classes)\n",
    "train_loader, val_loader = get_dataloaders(\n",
    "    dataset=dataset, transform=transform, batch_size=batch_size,\n",
    "    num_workers=num_workers, pin_memory=pin_memory\n",
    ")\n",
    "dataloaders = {'train': train_loader, 'val': val_loader}\n",
    "\n",
    "# setup model\n",
    "model_ft = GoogLeNet_Scalp(device=device, num_classes=num_classes)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr=lr, eps=eps, weight_decay=weight_decay)\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer_ft, step_size=step_size, gamma=gamma)\n",
    "\n",
    "model_ft = train_model(model_ft, dataloaders, criterion, optimizer_ft, lr_scheduler,\n",
    "                        num_epochs=num_epochs, device=device, augmenter=augmenter)\n",
    "# save model\n",
    "torch.save(model_ft.state_dict(), 'weights/model_checkpoint.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hair-deisease-cnn-project-sPLV6DJP-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
